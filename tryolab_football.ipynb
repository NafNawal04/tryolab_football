{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NafNawal04/tryolab_football.git\n",
        "%cd tryolab_football"
      ],
      "metadata": {
        "collapsed": true,
        "id": "B_pX_uMCK6qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SilvioGiancola/SoccerNetv2-DevKit.git soccernet/SoccerNetv2-DevKit\n",
        "%cd soccernet/SoccerNetv2-DevKit/Task1-ActionSpotting/CALF\n",
        "\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install SoccerNet\n",
        "\n",
        "# Install system dependencies\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "# Install Python packages\n",
        "!pip install -q scikit-video\n",
        "!pip install -q tensorflow==2.3.0\n",
        "!pip install -q imutils\n",
        "!pip install -q opencv-python==3.4.11.41\n",
        "!pip install -q SoccerNet\n",
        "!pip install -q moviepy\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q ffmpy\n",
        "!pip install -q torch torchvision"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ysc-n2ZTSBvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd soccernet/SoccerNetv2-DevKit/Task1-ActionSpotting/CALF\n",
        "from pathlib import Path\n",
        "\n",
        "preprocessing_path = Path(\"/content/tryolab_football/soccernet/SoccerNetv2-DevKit/Task1-ActionSpotting/CALF/inference/preprocessing.py\")\n",
        "\n",
        "old_stamp = (\n",
        "    \"            # tryolab_autopatch\\n\"\n",
        "    \"            copy_end = min(chunk_size - receptive_field, video_size, tmp_timestamps.size(0))\\n\"\n",
        "    \"            timestamps_long[0:copy_end] = tmp_timestamps[0:copy_end]\"\n",
        ")\n",
        "new_stamp = (\n",
        "    \"            # tryolab_autopatch\\n\"\n",
        "    \"            copy_end = max(0, min(chunk_size - receptive_field, video_size, tmp_timestamps.size(0)))\\n\"\n",
        "    \"            if copy_end:\\n\"\n",
        "    \"                timestamps_long[0:copy_end] = tmp_timestamps[0:copy_end]\"\n",
        ")\n",
        "\n",
        "old_stamp_seg = (\n",
        "    \"            # tryolab_autopatch\\n\"\n",
        "    \"            copy_end = min(chunk_size - receptive_field, video_size, tmp_segmentation.size(0))\\n\"\n",
        "    \"            segmentation_long[0:copy_end] = tmp_segmentation[0:copy_end]\"\n",
        ")\n",
        "new_stamp_seg = (\n",
        "    \"            # tryolab_autopatch\\n\"\n",
        "    \"            copy_end = max(0, min(chunk_size - receptive_field, video_size, tmp_segmentation.size(0)))\\n\"\n",
        "    \"            if copy_end:\\n\"\n",
        "    \"                segmentation_long[0:copy_end] = tmp_segmentation[0:copy_end]\"\n",
        ")\n",
        "\n",
        "text = preprocessing_path.read_text()\n",
        "text = text.replace(old_stamp, new_stamp)\n",
        "text = text.replace(old_stamp_seg, new_stamp_seg)\n",
        "preprocessing_path.write_text(text)\n",
        "print(\"Updated preprocessing.py with guarded copy length.\")"
      ],
      "metadata": {
        "id": "bgIgFYEZc2Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "dataset_path = Path(\n",
        "    \"/content/tryolab_football/soccernet/SoccerNetv2-DevKit/Task1-ActionSpotting/CALF/inference/dataset.py\"\n",
        ")\n",
        "\n",
        "target_fn = \"def feats2clip(feats, idx):\"\n",
        "new_fn = textwrap.dedent(\n",
        "    \"\"\"\n",
        "    def feats2clip(feats, idx):\n",
        "        \\\"\\\"\\\"Return a (chunk_size, feature_dim) tensor, zero-padding if idx goes outside range.\\\"\\\"\\\"\n",
        "        feature_dim = feats.size(1)\n",
        "\n",
        "        def _pad_and_copy(start_idx, stop_idx, step=1):\n",
        "            length = max(0, stop_idx - start_idx)\n",
        "            if length == 0:\n",
        "                return torch.zeros(0, feature_dim, dtype=feats.dtype)\n",
        "            pad_left = max(0, -start_idx)\n",
        "            pad_right = max(0, start_idx + length - feats.size(0))\n",
        "            start_idx_clamped = max(0, start_idx)\n",
        "            stop_idx_clamped = min(feats.size(0), start_idx + length)\n",
        "            clip = feats[start_idx_clamped:stop_idx_clamped:step]\n",
        "            if pad_left or pad_right or clip.size(0) < length:\n",
        "                padded = torch.zeros(length, feature_dim, dtype=feats.dtype)\n",
        "                if clip.size(0) > 0:\n",
        "                    padded[pad_left:pad_left + clip.size(0)] = clip\n",
        "                return padded\n",
        "            return clip\n",
        "\n",
        "        if isinstance(idx, slice):\n",
        "            start = idx.start or 0\n",
        "            stop = idx.stop if idx.stop is not None else feats.size(0)\n",
        "            step = idx.step or 1\n",
        "            if step != 1:\n",
        "                raise ValueError(\"feats2clip expects step=1 slices.\")\n",
        "            return _pad_and_copy(start, stop, step)\n",
        "\n",
        "        safe_idx = min(max(idx, 0), feats.size(0) - 1)\n",
        "        if safe_idx != idx:\n",
        "            return torch.zeros(feature_dim, dtype=feats.dtype)\n",
        "        return feats[safe_idx]\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "text = dataset_path.read_text(encoding=\"utf-8\")\n",
        "if target_fn not in text:\n",
        "    raise RuntimeError(\"Could not find feats2clip in dataset.py\")\n",
        "\n",
        "before, after = text.split(target_fn, maxsplit=1)\n",
        "after = after.split(\"def \", 1)[-1]\n",
        "dataset_path.write_text(before + new_fn + \"def \" + after, encoding=\"utf-8\")\n",
        "print(\"Updated feats2clip to clamp/zero-pad out-of-range slices.\")"
      ],
      "metadata": {
        "id": "iQtt8U0djF3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gd6gJQ0jwvb"
      },
      "source": [
        "\n",
        "\n",
        "> **In soccer-video-analytics folder, create two folders \"models\" and \"videos\". Then in models, add ball.pt file and in videos, add the soccer_possession.mp4 video**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/tryolab_football"
      ],
      "metadata": {
        "id": "KHzG0SH3ULVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!pip install numpy\n",
        "!pip install Pillow\n",
        "!pip install norfair[video]\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "collapsed": true,
        "id": "d4wLPnUVZhbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2wCYtnvBzRpY"
      },
      "outputs": [],
      "source": [
        "!python run.py --passes --possession --model models/ball.pt --video videos/short_vid.mp4 --soccernet"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}